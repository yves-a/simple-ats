services:
  # Python AI Service - Development Configuration
  python-ai:
    environment:
      - ENVIRONMENT=development
      - OLLAMA_URL=http://host.docker.internal:11434  # Connect to local Ollama
    extra_hosts:
      - "host.docker.internal:host-gateway"  # Enable connection to host machine
    depends_on: []  # Remove dependency on ollama service
    
  # Disable Ollama container in development (use local Ollama instead)
  ollama:
    profiles:
      - production  # Only start Ollama in production profile